{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfda85139b829953",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "tags": [
     "imports"
    ],
    "ExecuteTime": {
     "end_time": "2025-11-11T11:31:58.697554Z",
     "start_time": "2025-11-11T11:31:56.838218Z"
    }
   },
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "from models_temp import NonLinearController, ClosedLoopSystem\n",
    "from Rens import REN_IQC_gamma, DualREN\n",
    "from utils import set_params, set_QR, ensure_3d\n",
    "from torch.utils.data import DataLoader, random_split, Subset, SubsetRandomSampler\n",
    "from ParametersFunctions import Parameter, PID_functions, MinMaxScalerTorch\n",
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "from dataset import LoadData"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "bac06619dad4c6f1",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "54cb147241e0562d",
   "metadata": {
    "tags": [
     "set_params"
    ],
    "ExecuteTime": {
     "end_time": "2025-11-11T11:32:00.644043Z",
     "start_time": "2025-11-11T11:32:00.637936Z"
    }
   },
   "source": [
    "# Parameters\n",
    "# ------------\n",
    "# If ecxecuted with papermill these parameters are overwritten.\n",
    "\n",
    "patient = globals().get(\"patient\", None)\n",
    "device = globals().get(\"device\", None)\n",
    "\n",
    "# if not passed in papermill, set preferred values for manual use\n",
    "if patient is None:\n",
    "    patient = 1   # <-- preferred patient for manual use\n",
    "if device is None:\n",
    "    device = \"cpu\"  # <-- preferred device for manual use\n",
    "\n",
    "# can add like this more optional parameters like batch size, epochs, learning rate, etc.\n",
    "\n",
    "print(f\"[INFO] Training per patient: {patient}    on device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define simulation parameters\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "x0, input_dim, output_dim, dim_internal, dim_nl, y_init, IQC_type, gamma, learning_rate, epochs, data_path, model_folder, redo_save, ts, use_noise, num_days = set_params()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training per patient: 1    on device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "294c8f7659ab1bc7",
   "metadata": {},
   "source": [
    "# Closed-loop data"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa4d2163c9e3fe88",
   "metadata": {
    "tags": [
     "cl_data"
    ],
    "ExecuteTime": {
     "end_time": "2025-11-11T11:32:04.190200Z",
     "start_time": "2025-11-11T11:32:03.591077Z"
    }
   },
   "source": [
    "#-------------------------2. Generate closed loop data---------------------------------------------\n",
    "\n",
    "\n",
    "# consecutive days split\n",
    "train_size = int(num_days*0.8*1440//ts)\n",
    "val_size = int(num_days*0.1*1440//ts)\n",
    "test_size = int(num_days*0.1*1440//ts)\n",
    "\n",
    "start_valid = 5*12 # 5 hours of warm-up for validation and test\n",
    "\n",
    "# it is normalized, has as method also the scaler to denormalize\n",
    "dataset = LoadData(patient, data_path, use_noise, train_size+start_valid)\n",
    "\n",
    "\n",
    "val_dataset   = torch.utils.data.Subset(dataset, range(train_size+start_valid, train_size+start_valid + val_size))\n",
    "test_dataset  = torch.utils.data.Subset(dataset, range(train_size+start_valid + val_size, train_size + val_size + test_size))\n",
    "\n",
    "\n",
    "\n",
    "#------------------------- save scalers ---------------------------------------------------\n",
    "\n",
    "scaler_glucose = dataset.scaler_glucose\n",
    "scaler_insulin = dataset.scaler_insulin\n",
    "scaler_meal    = dataset.scaler_meal\n",
    "\n",
    "if redo_save:\n",
    "    # Save the scalers\n",
    "    # 1. Create models directory\n",
    "    patient_str = \"/paz_\" + str(int(patient)).zfill(3)\n",
    "    patient_model_folder = model_folder + \"/\" + patient_str\n",
    "    MODEL_PATH = Path(patient_model_folder)\n",
    "    MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "    # 2. save model state dict\n",
    "    torch.save(scaler_glucose, MODEL_PATH / 'scaler_glucose.pth')\n",
    "    torch.save(scaler_insulin, MODEL_PATH / 'scaler_insulin.pth')\n",
    "    torch.save(scaler_meal,    MODEL_PATH / 'scaler_meal.pth')\n",
    "    \n",
    "    sio.savemat(MODEL_PATH / 'scalers.mat', {\n",
    "    'glucose_low':  scaler_glucose.params['low'].item(),\n",
    "    'glucose_high': scaler_glucose.params['high'].item(),\n",
    "    'insulin_low':  scaler_insulin.params['low'].item(),\n",
    "    'insulin_high': scaler_insulin.params['high'].item(),\n",
    "    'meal_low':     scaler_meal.params['low'].item(),\n",
    "    'meal_high':    scaler_meal.params['high'].item()\n",
    "})\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "9ba463722c24562a",
   "metadata": {},
   "source": [
    "### Plots: I and R"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebebc3bbd2b9c9f2",
   "metadata": {
    "tags": [
     "plot_1"
    ],
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-11T11:32:15.312346Z"
    }
   },
   "source": [
    "CGM   = (scaler_glucose.denormalize(dataset.CGM.detach())).numpy();              G     = (scaler_glucose.denormalize(dataset.G.detach())).numpy()\n",
    "                                                                                                                                 \n",
    "I_sat       = (scaler_insulin.denormalize(dataset.I_sat.detach())).numpy();      I_rec = (scaler_insulin.denormalize(dataset.I_rec.detach())).numpy();       \n",
    "I_sat_rec   = (scaler_insulin.denormalize(dataset.I_sat_rec.detach())).numpy();  R     = (scaler_insulin.denormalize(dataset.R.detach())).numpy()\n",
    "\n",
    "M       = (scaler_meal.denormalize(dataset.M.detach())).numpy();                 MH    = (scaler_meal.denormalize(dataset.MH.detach())).numpy();          \n",
    "MH_rec  = (scaler_meal.denormalize(dataset.MH_rec.detach())).numpy()\n",
    "H       = (scaler_meal.denormalize(dataset.H.detach())).numpy();                 H_rec = (scaler_meal.denormalize(dataset.H_rec.detach())).numpy();     \n",
    "\n",
    "# R = I_sat (from .mat) - I_rec (exiting the PID and before saturation and noise)\n",
    "# if  use_noise = True, R contains the noise and the saturation effect\n",
    "\n",
    "\n",
    "# ------------------------- PID controller dynamic simulation ---------------------------------------------------\n",
    "CGM_torch = dataset.CGM\n",
    "time = dataset.time\n",
    "loaded_parameters = Parameter(patient)\n",
    "controller = NonLinearController(loaded_parameters, PID_functions, dataset.basal_vec, scaler_glucose, scaler_insulin, scaler_meal, use_noise)\n",
    "u_pid, u_pid_rwgn, u_pid_rwgn_sat, r = controller(CGM_torch, time)\n",
    "\n",
    "\n",
    "u_pid           = scaler_insulin.denormalize(u_pid.detach())\n",
    "u_pid_rwgn      = scaler_insulin.denormalize(u_pid_rwgn.detach())\n",
    "u_pid_rwgn_sat  = scaler_insulin.denormalize(u_pid_rwgn_sat.detach())\n",
    "r               = scaler_insulin.denormalize(r.detach())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(I_rec[:2*1440//ts]+ R[:2*1440//ts], label= 'I_rec + R')\n",
    "plt.plot(u_pid_rwgn_sat.numpy()[:2*1440//ts], label = 'I pid dynamic calculation');             plt.legend();plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(R[:2*1440//ts], label= 'R')\n",
    "plt.plot(r.numpy()[:2*1440//ts], label = 'R dynamic calculation');                             plt.legend();plt.grid(True); plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pmong\\OneDrive - Università di Pavia\\EPFL\\Nonlinear_system_identification_modified\\models_temp.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  basal = torch.tensor(basal, dtype=torch.float32)\n",
      "C:\\Users\\pmong\\OneDrive - Università di Pavia\\EPFL\\Nonlinear_system_identification_modified\\models_temp.py:113: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bolus = torch.tensor(bolus, dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9725b9ca",
   "metadata": {},
   "source": [
    "### create multiple batches for train"
   ]
  },
  {
   "cell_type": "code",
   "id": "9486fba7",
   "metadata": {},
   "source": [
    "# train ha 5 ore in più\n",
    "# devo eliminare 5 ore anche dal training se\n",
    "# recuperare gli starting saturation error aquando taglio i numerosi batch\n",
    "# provare se plottando batch per volta ottengo stesso risultato\n",
    "# tagliare ogni due giorni\n",
    "\n",
    "\n",
    "# time definitions\n",
    "ts_per_hour = 12           # 288 timesteps = 24h → 12 timesteps/hour (5 min each)\n",
    "hours_per_batch = 48       # 2 days = 48 hours\n",
    "steps_per_batch = hours_per_batch * ts_per_hour  # 48*12 = 576\n",
    "\n",
    "start_train = start_valid        #I eliminate eqully the first 5 hours from training set\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, range(start_train, train_size+start_valid))\n",
    "\n",
    "\n",
    "# === FUNZIONE: crea blocchi fissi ===\n",
    "def create_fixed_batches(total_length, chunk_size=576, start_idx=0):\n",
    "    \"\"\"\n",
    "    Divide il dataset in batch temporali fissi (48h).\n",
    "    Ogni batch è una lista di indici consecutivi.\n",
    "    L'ultimo batch viene scartato se più corto di chunk_size.\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    start = start_idx\n",
    "    while start + chunk_size <= total_length:\n",
    "        end = start + chunk_size\n",
    "        batches.append(list(range(start, end)))\n",
    "        start = end\n",
    "    return batches\n",
    "\n",
    "\n",
    "# === COSTRUISCI I BATCH INDICI ===\n",
    "train_indices = create_fixed_batches(len(train_dataset), chunk_size=steps_per_batch)\n",
    "\n",
    "starting_indices = [batch[0] for batch in train_indices]\n",
    "\n",
    "# === CUSTOM SAMPLER ===\n",
    "class BatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, batches):\n",
    "        self.batches = batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "\n",
    "# === DATALOADER ===\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=BatchSampler(train_indices),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Se glucose_PID non parte con gli stessi valori della simulazione originale (per esempio primi 5 campioni del batch sono tagliati o glucose_PID è differente), la somma integrale cambia → bolus diverso → R dinamico diverso.\n",
    "\n",
    "# === LOOP DI TRAINING ===\n",
    "for n_batch, (u0_batch, _, _, u1_batch, y_batch, time_batch) in enumerate(train_loader):\n",
    "    batch_starting_sat_e = dataset.sat_e[starting_indices][n_batch]\n",
    "    starting_index = starting_indices[n_batch]\n",
    "    previous_25 = np.arange(starting_index  - (loaded_parameters.PID_par.integral_duration)-1, starting_index )\n",
    "    \n",
    "    if any(previous_25 < 0):\n",
    "        glucose_PID_init = None\n",
    "    else:\n",
    "        glucose_PID_init = scaler_glucose.denormalize(dataset.CGM[previous_25])\n",
    "        \n",
    "    \n",
    "    u_pid, u_pid_rwgn, u_pid_rwgn_sat, r = controller(CGM = y_batch, time = time, \n",
    "                                                      saturation_error_init = scaler_insulin.denormalize(batch_starting_sat_e), \n",
    "                                                      glucose_PID_init = glucose_PID_init)\n",
    "    \n",
    "    r = scaler_insulin.denormalize(r.detach())\n",
    "    print(u0_batch.shape, y_batch.shape, batch_starting_sat_e)\n",
    "    plt.figure()\n",
    "    plt.plot(time_batch.squeeze().numpy(), R[time_batch.squeeze().numpy().astype(int)], label= 'R')\n",
    "    plt.plot(time_batch.squeeze().numpy(), r.numpy(), label = 'R dynamic calculation');                             plt.legend();plt.grid(True); plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "098e2636",
   "metadata": {},
   "source": [
    "### other plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f50a1f855fed7e",
   "metadata": {
    "tags": [
     "plot_2"
    ]
   },
   "source": [
    "plt.figure(1, figsize=(12, 8))\n",
    "\n",
    "# Subplot 1\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(CGM[:], 'b-', label='Glucose sensor CGM')\n",
    "ax1.plot(G[:], 'gray', label='Glucose');                                                               ax1.set_ylabel('Glucose', color='b'); ax1.tick_params(axis='y', labelcolor='b'); ax1_right = ax1.twinx()\n",
    "MHtemp = MH[:].copy()\n",
    "ax1_right.scatter(np.arange(len(MHtemp))[MHtemp!=0], MHtemp[MHtemp!=0], color='g', label='Meals and hypo');         ax1_right.set_ylabel('Meals', color='b'); ax1_right.tick_params(axis='y', labelcolor='g'); plt.grid(True)\n",
    "\n",
    "# Subplot 2\n",
    "ax2 = plt.subplot(2, 1, 2, sharex=ax1)\n",
    "ax2.plot(range(len(I_sat[:])), I_sat[:].flatten(), label='I_sat')\n",
    "ax2.plot(range(len(I_sat_rec[:])), I_sat_rec[:], label='I_sat_rec');                                      ax2.set_ylim([0, np.max(I_sat_rec) * 1.1]); ax2.legend(); ax2.set_xlabel('Time Index'); ax2.set_ylabel('Insulin')\n",
    "\n",
    "plt.tight_layout(); plt.grid(True); plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(3, figsize=(12, 8))\n",
    "plt.plot(I_rec[:1440//4]+ R[:1440//4], label = 'I_rec(calculated by PID) + R')\n",
    "plt.plot(I_sat[:1440//4], label= 'I_sat (from the data already saturated)')\n",
    "plt.title('I saturated, They need to be equal,   R = I_sat - I_rec');                   plt.legend();plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure(4, figsize=(12, 8))\n",
    "plt.plot(R[:1440//4], label= 'R')\n",
    "plt.plot(I_rec[:1440//4]+ R[:1440//4], label= 'I_rec + R')\n",
    "plt.plot(I_rec[:1440//4], label = 'I_rec  (calculated by PID)');                             plt.legend();plt.grid(True); plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(5)\n",
    "# plt.plot(H, label='H')\n",
    "# plt.plot(H_rec-100, label='H_rec')\n",
    "# plt.title('Hypoglycemia Treatments Comparison');                                                    plt.legend(); plt.show()\n",
    "#\n",
    "# plt.figure(6)\n",
    "# plt.plot(CGM[:1440//4], 'b-', label='Glucose sensor CGM')\n",
    "# plt.plot(G[:1440//4], 'gray', label='Glucose')\n",
    "# plt.figure(1, figsize=(12, 8))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ae7178832c8e180",
   "metadata": {
    "tags": [
     "strategy_1"
    ]
   },
   "source": [
    "# 1 System identification of G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5205f83f921f3f7",
   "metadata": {},
   "source": [
    "### REN model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1ad89e848d79708",
   "metadata": {
    "tags": [
     "strat_1_def_ren"
    ]
   },
   "source": [
    "#--------------------------3. Define model for sysid---------------------------------------------\n",
    "\n",
    "\n",
    "device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# meal   M \n",
    "REN_0 = REN_IQC_gamma(dim_in= input_dim[0], dim_out= output_dim[0], dim_internal=dim_internal[0], dim_nl= dim_nl[0], y_init = y_init[0], QR_fun = set_QR, gammat=gamma[0], IQC_type = IQC_type[0], device=device)\n",
    "\n",
    "# insulin  I_sat\n",
    "REN_1 = REN_IQC_gamma(dim_in= input_dim[1], dim_out= output_dim[1], dim_internal=dim_internal[1], dim_nl= dim_nl[1], y_init = y_init[1], QR_fun = set_QR, gammat=gamma[1], IQC_type = IQC_type[1], device=device)\n",
    "\n",
    "REN_0 = REN_0.to(device)\n",
    "REN_1 = REN_1.to(device)\n",
    "\n",
    "#create the closed loop with the identified model\n",
    "# closed_loop_G = ClosedLoopSystem(REN_G, controller)\n",
    "\n",
    "#--------------------------4. Define the loss function and optimizer---------------------------------------------\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam( list(REN_0.parameters()) + list(REN_1.parameters()),   lr=learning_rate)\n",
    "optimizer.zero_grad()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5fb92b7c27b82404",
   "metadata": {},
   "source": [
    "### Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "dff2d110",
   "metadata": {
    "tags": [
     "strat_1_train_valid"
    ]
   },
   "source": [
    "#--------------------------5. Training---------------------------------------------------------------------\n",
    "\n",
    "torch.set_default_device(device)      # default tensor device\n",
    "torch.set_default_dtype(torch.float32)  # default tensor dtype\n",
    "print(f\"[INFO] Training on device: {device}\")\n",
    "\n",
    "REN_0.to(device); REN_1.to(device)\n",
    "train_losses = []\n",
    "val_losses = []  # Store validation losses across epochs\n",
    "for epoch in range(epochs):\n",
    "    # ---------------- TRAINING ---------------- #\n",
    "    REN_0.train(); REN_1.train()\n",
    "    loss_epoch = 0.0  # Accumulate training loss\n",
    "\n",
    "    \n",
    "    for u0_batch, _, _, u1_batch, y_batch, _ in train_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "        \n",
    "        u0_batch, u1_batch, y_batch= ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch) # batch_size, time_horizon, input_dim\n",
    "        u0_batch, u1_batch, y_batch = u0_batch.to(device), u1_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        REN_0.reset(); REN_1.reset()\n",
    "\n",
    "        y0_hat_train = REN_0(u0_batch) # forward\n",
    "        y1_hat_train = REN_1(u1_batch) # forward\n",
    "        y_hat_train = y0_hat_train - y1_hat_train \n",
    "        # with monotonicity we have forced a positive response from the insulin REN (REN_1) \n",
    "        # but from real-world knowledge it is a negative relation\n",
    "\n",
    "        loss_batch = MSE(y_hat_train, y_batch)\n",
    "\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss_batch.item()\n",
    "\n",
    "    loss_epoch /= len(train_loader)\n",
    "    train_losses.append(loss_epoch)\n",
    "\n",
    "    # ---------------- VALIDATION ---------------- #\n",
    "    REN_0.eval(); REN_1.eval()\n",
    "    loss_val_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u0_batch, _, _, u1_batch, y_batch, _ in val_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "\n",
    "            u0_batch, u1_batch, y_batch= ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch)\n",
    "            u0_batch, u1_batch, y_batch = u0_batch.to(device), u1_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            REN_0.reset(); REN_1.reset()\n",
    "\n",
    "            y0_hat_val = REN_0(u0_batch)\n",
    "            y1_hat_val = REN_1(u1_batch)# select the correct U\n",
    "            y_hat_val = y0_hat_val - y1_hat_val\n",
    "            \n",
    "            loss_batch_val = MSE(y_hat_val, y_batch)\n",
    "\n",
    "            loss_val_epoch += loss_batch_val.item()\n",
    "\n",
    "    if epoch == 0 or loss_val_epoch < min_val_loss:\n",
    "        min_val_loss = loss_val_epoch\n",
    "        epoch_when_model_saved = epoch\n",
    "        candidate_REN_0 = REN_0\n",
    "        candidate_REN_1 = REN_1\n",
    "\n",
    "    loss_val_epoch /= len(val_loader)\n",
    "    val_losses.append(loss_val_epoch)  # Store validation loss for plotting\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} \\t||\\t Training Loss: {loss_epoch:.6f} \\t||\\t Validation Loss: {loss_val_epoch:.6f}\")\n",
    "\n",
    "if redo_save:\n",
    "    # model on CPU before saving\n",
    "    candidate_REN_0_cpu = candidate_REN_0.to('cpu')\n",
    "    candidate_REN_1_cpu = candidate_REN_1.to('cpu')\n",
    "\n",
    "    # Save the best model\n",
    "    # 1. Create models directory\n",
    "    patient_str = \"/paz_\" + str(int(patient)).zfill(3)\n",
    "    patient_model_folder = model_folder + \"/\"+ \"strategy_1\" + \"/\" + patient_str\n",
    "    MODEL_PATH = Path(patient_model_folder)\n",
    "    MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "    # 2. save model state dict\n",
    "    torch.save({\n",
    "    'REN_0_state_dict': candidate_REN_0_cpu.state_dict(),\n",
    "    'REN_1_state_dict': candidate_REN_1_cpu.state_dict()}, MODEL_PATH / 'trained_models.pth')\n",
    "\n",
    "\n",
    "    # save .mat\n",
    "    np_x0 = x0.detach().cpu().numpy(); np_input_dim = np.array(input_dim); np_output_dim = np.array(output_dim); np_dim_internal =np.array(dim_internal); np_dim_nl = np.array(dim_nl)\n",
    "    np_y_init = y_init.cpu().numpy(); np_gamma = gamma.cpu().numpy()\n",
    "    \n",
    "    # 4. Create params directory\n",
    "    params_folder = Path(patient_model_folder) / \"params\"\n",
    "    params_folder.mkdir(parents=True, exist_ok=True)\n",
    "    scipy.io.savemat(params_folder / 'parameters.mat', {'train_losses': train_losses, 'val_losses': val_losses, 'epoch_when_model_saved': epoch_when_model_saved, 'x0': np_x0, 'input_dim': np_input_dim, 'output_dim': np_output_dim, 'dim_internal': np_dim_internal, 'dim_nl': np_dim_nl, 'y_init': np_y_init, 'gamma': np_gamma})\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e91c20737fb3c13",
   "metadata": {},
   "source": [
    "### Plots: identification results for G"
   ]
  },
  {
   "cell_type": "code",
   "id": "db8fe8e4fccc6349",
   "metadata": {
    "tags": [
     "plot_strat_1_test_1"
    ]
   },
   "source": [
    "# --------------Plot identification results for G-----------------\n",
    "\n",
    "#Training and Validation Loss Across Epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss', color='red')  # Assuming val_losses are collected\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Across Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Model's Predictions vs Actual Output for the test set\n",
    "fig, axes = plt.subplots(nrows=len(test_loader), ncols=1, figsize=(8, 12), sharex=True, sharey=True)\n",
    "REN_0.to(\"cpu\"); REN_1.to(\"cpu\")\n",
    "\n",
    "for u0_batch, _, _, u1_batch, y_batch, time in test_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time:\n",
    "    \n",
    "    u0_batch, u1_batch, y_batch= ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch)\n",
    "    u0_batch, u1_batch, y_batch = u0_batch.to(\"cpu\"), u1_batch.to(\"cpu\"), y_batch.to(\"cpu\")\n",
    "    # Plot comparison between real and predicted for training set\n",
    "    REN_0.eval(); REN_1.eval()\n",
    "\n",
    "    y0_hat = REN_0(u0_batch)\n",
    "    y1_hat = REN_1(u1_batch)# select the correct U\n",
    "    y_hat = y0_hat - y1_hat\n",
    "    \n",
    "    y_batch_np = scaler_glucose.denormalize(y_batch.detach().cpu()).numpy()\n",
    "    y_hat_np = scaler_glucose.denormalize(y_hat.detach().cpu()).numpy()\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(time, y_batch_np[0, :, 0], label=\"Real Output\", color=\"blue\")\n",
    "plt.plot(time, y_hat_np[0, :, 0], label=\"Predicted Output\", linestyle=\"--\", color=\"orange\")\n",
    "plt.title(f\"Train Set\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Output Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9043b18e1e4e2490",
   "metadata": {},
   "source": [
    "# System identification of the negative feedback of K and S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea261367e35655b",
   "metadata": {},
   "source": [
    "### Closed loop model of REN in negative feedback with K, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b0c9095b9c339",
   "metadata": {
    "tags": [
     "strat_2_def_ren"
    ]
   },
   "source": [
    "#-----------------------------closedloop sysid of S through RENs------------------------\n",
    "#--------------------------Define model for sysid---------------------------------------------\n",
    "#create the REN model for S\n",
    "\n",
    "y_init = x0\n",
    "\n",
    "\n",
    "REN_0 = REN_IQC_gamma(dim_in= input_dim[0], dim_out= output_dim[0], dim_internal=dim_internal[0], dim_nl= dim_nl[0], y_init = y_init[0], QR_fun = set_QR, gammat=gamma[0], IQC_type = IQC_type[0], device=device)\n",
    "\n",
    "REN_S = REN_IQC_gamma(dim_in= input_dim[1], dim_out= output_dim[1], dim_internal=dim_internal[1], dim_nl= dim_nl[1], y_init = y_init[1], QR_fun = set_QR, gammat=gamma[1], IQC_type = IQC_type[1], device=device)\n",
    "Dual_REN = DualREN(REN_0, REN_S, device=device)\n",
    "controller = NonLinearController(loaded_parameters, PID_functions, dataset.basal_vec, scaler_glucose, scaler_insulin, scaler_meal, use_noise)\n",
    "closed_loop_REN = ClosedLoopSystem(Dual_REN, controller, negative=True)\n",
    "\n",
    "closed_loop_closed_loop_1 = ClosedLoopSystem(closed_loop_REN, controller)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------Define the loss function and optimizer---------------------------------------------\n",
    "MSE = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Dual_REN.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e85915de5878542",
   "metadata": {},
   "source": [
    "### Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "b363ac2ca7aff476",
   "metadata": {
    "tags": [
     "strat_2_train_valid"
    ]
   },
   "source": [
    "#--------------------------5. Training---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "REN_0 = REN_0.to(device)\n",
    "REN_S = REN_S.to(device)\n",
    "Dual_Ren = Dual_REN.to(device)\n",
    "controller = controller.to(device)\n",
    "closed_loop_REN = closed_loop_REN.to(device)\n",
    "x0 = x0.to(device)\n",
    "print(f\"[INFO] Training on device: {device}\")\n",
    "\n",
    "closed_loop_closed_loop_1 = closed_loop_closed_loop_1.to(\"cpu\") # test always on cpu?\n",
    "torch.set_default_dtype(torch.float32)  # default tensor dtype\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []  # Store validation losses across epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---------------- TRAINING ---------------- #\n",
    "    closed_loop_REN.train()\n",
    "    loss_epoch = 0.0  # Accumulate training loss\n",
    "\n",
    "\n",
    "    for u0_batch, _, _, u1_batch, y_batch, t_batch in train_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "        # u_batch.shape = batch_size   horizon   input_dim\n",
    "        \n",
    "        u0_batch, u1_batch, y_batch, t_batch = ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch), ensure_3d(t_batch) # batch_size, time_horizon, input_dim\n",
    "        u0_batch, u1_batch, y_batch, t_batch = u0_batch.to(device), u1_batch.to(device), y_batch.to(device), t_batch.to(device)\n",
    "        u_batch = torch.cat((u0_batch, u1_batch), dim=2)  # concatenate along input dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Dual_REN.reset(); \n",
    "        # closed_loop_REN.reset() ?\n",
    "        \n",
    "        _, y_hat_train = closed_loop_REN(x0, u_batch, t_batch)\n",
    "\n",
    "        if torch.isnan(y_hat_train).any() or torch.isinf(y_hat_train).any():\n",
    "            y_hat_train = torch.nan_to_num(y_hat_train, nan=1e5, posinf=1e5, neginf=-1e5)\n",
    "            for name, param in closed_loop_REN.named_parameters():\n",
    "                print(f\"{name}: mean {param.data.mean()}, std {param.data.std()}\")\n",
    "\n",
    "        loss_batch = MSE(y_hat_train, y_batch)\n",
    "\n",
    "        loss_batch.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss_batch.item()\n",
    "\n",
    "    loss_epoch /= len(train_loader)\n",
    "    train_losses.append(loss_epoch)\n",
    "\n",
    "    # ---------------- VALIDATION ---------------- #\n",
    "    Dual_REN.eval()\n",
    "    loss_val_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u0_batch, _, _, u1_batch, y_batch, t_batch in val_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "            # u_batch.shape = batch_size   horizon   input_dim\n",
    "            \n",
    "            u0_batch, u1_batch, y_batch, t_batch = ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch), ensure_3d(t_batch) # batch_size, time_horizon, input_dim\n",
    "            u_batch = torch.cat((u0_batch, u1_batch), dim=2)  # concatenate along input dimension\n",
    "            u_batch, y_batch, t_batch = u_batch.to(device), y_batch.to(device), t_batch.to(device)\n",
    "            \n",
    "            Dual_REN.reset(); \n",
    "\n",
    "            _, y_hat_val = closed_loop_REN(x0, u_batch, t_batch)\n",
    "            \n",
    "            loss_batch_val = MSE(y_hat_val, y_batch)\n",
    "\n",
    "            loss_val_epoch += loss_batch_val.item()\n",
    "\n",
    "    if epoch == 0 or loss_val_epoch < min_val_loss:\n",
    "        min_val_loss = loss_val_epoch\n",
    "        epoch_when_model_saved = epoch\n",
    "        candidate_Dual_REN = Dual_REN\n",
    "\n",
    "    loss_val_epoch /= len(val_loader)\n",
    "    val_losses.append(loss_val_epoch)  # Store validation loss for plotting\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} \\t||\\t Training Loss: {loss_epoch:.6f} \\t||\\t Validation Loss: {loss_val_epoch:.6f}\")\n",
    "\n",
    "if redo_save:\n",
    "    # model on CPU before saving\n",
    "    candidate_Dual_REN_cpu = candidate_Dual_REN.to('cpu')\n",
    "\n",
    "    # Save the best model\n",
    "    # 1. Create models directory\n",
    "    patient_str = \"/paz_\" + str(int(patient)).zfill(3)\n",
    "    patient_model_folder = model_folder + \"/\"+ \"strategy_2\" + \"/\" + patient_str\n",
    "    MODEL_PATH = Path(patient_model_folder)\n",
    "    MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "    # 2. save model state dict\n",
    "    torch.save({\n",
    "    'Dueal_REN_state_dict': candidate_Dual_REN_cpu.state_dict()}, MODEL_PATH / 'trained_models.pth')\n",
    "\n",
    "\n",
    "    # save .mat\n",
    "    np_x0 = x0.detach().cpu().numpy(); np_input_dim = np.array(input_dim); np_output_dim = np.array(output_dim); np_dim_internal =np.array(dim_internal); np_dim_nl = np.array(dim_nl)\n",
    "    np_y_init = y_init.cpu().numpy(); np_gamma = gamma.cpu().numpy()\n",
    "    \n",
    "    # 4. Create params directory\n",
    "    params_folder = Path(patient_model_folder) / \"params\"\n",
    "    params_folder.mkdir(parents=True, exist_ok=True)\n",
    "    scipy.io.savemat(params_folder / 'parameters.mat', {'train_losses': train_losses, 'val_losses': val_losses, 'epoch_when_model_saved': epoch_when_model_saved, 'x0': np_x0, 'input_dim': np_input_dim, 'output_dim': np_output_dim, 'dim_internal': np_dim_internal, 'dim_nl': np_dim_nl, 'y_init': np_y_init, 'gamma': np_gamma})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a602ddd5db81f71b",
   "metadata": {},
   "source": [
    "### Plots: identification results for the negative feedback of S and K"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a34a37504695c74",
   "metadata": {
    "tags": [
     "plot_strat_2_test_1"
    ]
   },
   "source": [
    "# --------------Plot identification results for S-----------------\n",
    "\n",
    "#Training and Validation Loss Across Epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss', color='red')  # Assuming val_losses are collected\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Across Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Model's Predictions vs Actual Output for the test set\n",
    "fig, axes = plt.subplots(nrows=len(test_loader), ncols=1, figsize=(8, 12), sharex=True, sharey=True)\n",
    "\n",
    "Dual_REN.to(\"cpu\"); closed_loop_REN.to(\"cpu\")\n",
    "    \n",
    "\n",
    "for u0_batch, _, _, u1_batch, y_batch, t_batch in test_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "    # u_batch.shape = batch_size   horizon   input_dim\n",
    "    \n",
    "    u0_batch, u1_batch, y_batch, t_batch= ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch), ensure_3d(t_batch) # batch_size, time_horizon, input_dim\n",
    "    u_batch = torch.cat((u0_batch, u1_batch), dim=2)  # concatenate along input dimension\n",
    "    u_batch, y_batch, t_batch = u_batch.to(\"cpu\"), y_batch.to(\"cpu\"), t_batch.to(\"cpu\")\n",
    "    \n",
    "\n",
    "    Dual_REN.eval()\n",
    "    _, y_hat = closed_loop_REN(x0, u_batch, t_batch)\n",
    "    \n",
    "    loss_batch_val = MSE(y_batch, y_hat)\n",
    "\n",
    "    loss_val_epoch += loss_batch_val.item()\n",
    "    \n",
    "    y_batch_np = scaler_glucose.denormalize(y_batch.detach().cpu()).numpy()\n",
    "    y_hat_np = scaler_glucose.denormalize(y_hat.detach().cpu()).numpy()\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(time, y_batch_np[0, :, 0], label=\"Real Output\", color=\"blue\")\n",
    "plt.plot(time, y_hat_np[0, :, 0], label=\"Predicted Output\", linestyle=\"--\", color=\"orange\")\n",
    "plt.title(f\"Train Set\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Output Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd11bed421338d08",
   "metadata": {},
   "source": [
    "# System identification of S using reference inputs"
   ]
  },
  {
   "cell_type": "code",
   "id": "b04f67db4e521a3c",
   "metadata": {
    "tags": [
     "strat_3_def_ren"
    ]
   },
   "source": [
    "#-----------------------------closedloop sysid of S through RENs------------------------\n",
    "#--------------------------Define model for sysid---------------------------------------------\n",
    "#create the REN model for S\n",
    "y_init = x0\n",
    "\n",
    "REN_0 = REN_IQC_gamma(dim_in= input_dim[0], dim_out= output_dim[0], dim_internal=dim_internal[0], dim_nl= dim_nl[0], y_init = y_init[0], QR_fun = set_QR, gammat=gamma[0], IQC_type = IQC_type[0], device=device)\n",
    "\n",
    "REN_S_2 = REN_IQC_gamma(dim_in= input_dim[1], dim_out= output_dim[1], dim_internal=dim_internal[1], dim_nl= dim_nl[1], y_init = y_init[1], QR_fun = set_QR, gammat=gamma[1], IQC_type = IQC_type[1], device=device)\n",
    "\n",
    "\n",
    "#--------------------------Define the loss function and optimizer---------------------------------------------\n",
    "MSE = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam( list(REN_0.parameters()) + list(REN_S_2.parameters()),   lr=learning_rate)\n",
    "optimizer.zero_grad()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b629cd1900bd86a0",
   "metadata": {},
   "source": [
    "### Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac63650993de14e2",
   "metadata": {
    "tags": [
     "strat_3_train_valid"
    ]
   },
   "source": [
    "#--------------------------5. Training---------------------------------------------------------------------\n",
    "\n",
    "REN_0 = REN_0.to(device)\n",
    "REN_S_2 = REN_S_2.to(device)\n",
    "print(f\"[INFO] Training on device: {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.float32)  # default tensor dtype\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []  # Store validation losses across epochs\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---------------- TRAINING ---------------- #\n",
    "    REN_0.train(); REN_S_2.train()\n",
    "    loss_epoch = 0.0  # Accumulate training loss\n",
    "\n",
    "    for u0_batch, _, u1_batch, _, y_batch, _ in train_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "        # u_batch.shape = batch_size   horizon   input_dim\n",
    "        u0_batch, u1_batch, y_batch = ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch) # batch_size, time_horizon, input_dim\n",
    "        u0_batch, u1_batch, y_batch = u0_batch.to(device), u1_batch.to(device), y_batch.to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        REN_0.reset(); REN_S_2.reset()\n",
    "        \n",
    "        \n",
    "        y0_hat_train = REN_0(u0_batch) # forward\n",
    "        y1_hat_train = REN_S_2(u1_batch) # forward\n",
    "        y_hat_train = y0_hat_train - y1_hat_train \n",
    "        # with monotonicity we have forced a positive response from the insulin REN (REN_1) \n",
    "        # but from real-world knowledge it is a negative relation\n",
    "\n",
    "        loss_batch = MSE(y_hat_train, y_batch)\n",
    "        \n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss_batch.item()\n",
    "\n",
    "    loss_epoch /= len(train_loader)\n",
    "    train_losses.append(loss_epoch)\n",
    "\n",
    "    # ---------------- VALIDATION ---------------- #\n",
    "    REN_0.eval(); REN_S_2.eval()\n",
    "    loss_val_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u0_batch, _, u1_batch, _, y_batch, _ in val_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "            # u_batch.shape = batch_size   horizon   input_dim\n",
    "            \n",
    "            u0_batch, u1_batch, y_batch= ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch) # batch_size, time_horizon, input_dim\n",
    "            u0_batch, u1_batch, y_batch = u0_batch.to(device), u1_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            REN_0.reset(); REN_S_2.reset()\n",
    "            \n",
    "            y0_hat_val = REN_0(u0_batch) # forward\n",
    "            y1_hat_val = REN_S_2(u1_batch) # forward\n",
    "            y_hat_val = y0_hat_val - y1_hat_val\n",
    "            \n",
    "            loss_batch_val = MSE(y_hat_val, y_batch)\n",
    "\n",
    "            loss_val_epoch += loss_batch_val.item()\n",
    "\n",
    "    if epoch == 0 or loss_val_epoch < min_val_loss:\n",
    "        min_val_loss = loss_val_epoch\n",
    "        epoch_when_model_saved = epoch\n",
    "        candidate_REN_0 = REN_0\n",
    "        candidate_REN_S_2 = REN_S_2\n",
    "\n",
    "    loss_val_epoch /= len(val_loader)\n",
    "    val_losses.append(loss_val_epoch)  # Store validation loss for plotting\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} \\t||\\t Training Loss: {loss_epoch:.6f} \\t||\\t Validation Loss: {loss_val_epoch:.6f}\")\n",
    "\n",
    "if redo_save:\n",
    "    # model on CPU before saving\n",
    "    candidate_REN_0_cpu = candidate_REN_0.to('cpu')\n",
    "    candidate_REN_S_2_cpu = candidate_REN_S_2.to('cpu')\n",
    "\n",
    "    # Save the best model\n",
    "    # 1. Create models directory\n",
    "    patient_str = \"/paz_\" + str(int(patient)).zfill(3)\n",
    "    patient_model_folder = model_folder + \"/\"+ \"strategy_3\" + \"/\" + patient_str\n",
    "    MODEL_PATH = Path(patient_model_folder)\n",
    "    MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "    # 2. save model state dict\n",
    "    torch.save({\n",
    "    'REN_0_state_dict': candidate_REN_0_cpu.state_dict(),\n",
    "    'REN_S_2_state_dict': candidate_REN_S_2_cpu.state_dict()}, MODEL_PATH / 'trained_models.pth')\n",
    "\n",
    "\n",
    "    # save .mat\n",
    "    np_x0 = x0.detach().cpu().numpy(); np_input_dim = np.array(input_dim); np_output_dim = np.array(output_dim); np_dim_internal =np.array(dim_internal); np_dim_nl = np.array(dim_nl)\n",
    "    np_y_init = y_init.cpu().numpy(); np_gamma = gamma.cpu().numpy()\n",
    "    \n",
    "    # 4. Create params directory\n",
    "    params_folder = Path(patient_model_folder) / \"params\"\n",
    "    params_folder.mkdir(parents=True, exist_ok=True)\n",
    "    scipy.io.savemat(params_folder / 'parameters.mat', {'train_losses': train_losses, 'val_losses': val_losses, 'epoch_when_model_saved': epoch_when_model_saved, 'x0': np_x0, 'input_dim': np_input_dim, 'output_dim': np_output_dim, 'dim_internal': np_dim_internal, 'dim_nl': np_dim_nl, 'y_init': np_y_init, 'gamma': np_gamma})\n",
    "    \n",
    "Dual_REN = DualREN(candidate_REN_0_cpu, candidate_REN_S_2_cpu)\n",
    "controller = NonLinearController(loaded_parameters, PID_functions, dataset.basal_vec, scaler_glucose, scaler_insulin, scaler_meal, use_noise)\n",
    "closed_loop_REN_2 = ClosedLoopSystem(Dual_REN, controller, negative=True)\n",
    "\n",
    "closed_loop_closed_loop_2 = ClosedLoopSystem(closed_loop_REN_2, controller)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "10ac3923d2805f9c",
   "metadata": {},
   "source": [
    "### Plots: identification results"
   ]
  },
  {
   "cell_type": "code",
   "id": "86fe3d3c6a18a8c3",
   "metadata": {
    "tags": [
     "plot_strat_3_test_1"
    ]
   },
   "source": [
    "# --------------Plot identification results for S-----------------\n",
    "\n",
    "#Training and Validation Loss Across Epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(epochs), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(epochs), val_losses, label='Validation Loss', color='red')  # Assuming val_losses are collected\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Across Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Model's Predictions vs Actual Output for the test set\n",
    "fig, axes = plt.subplots(nrows=len(test_loader), ncols=1, figsize=(8, 12), sharex=True, sharey=True)\n",
    "\n",
    "closed_loop_REN_2.to(\"cpu\")\n",
    "\n",
    "for u0_batch, _, _, u1_batch, y_batch, t_batch in test_loader: # MH, I_rec (PID), R (noise + sat), I_sat (I_rec + R), CGM, time\n",
    "    # u_batch.shape = batch_size   horizon   input_dim\n",
    "    \n",
    "    u0_batch, u1_batch, y_batch, t_batch = ensure_3d(u0_batch), ensure_3d(u1_batch), ensure_3d(y_batch), ensure_3d(t_batch) # batch_size, time_horizon, input_dim\n",
    "    u_batch = torch.cat((u0_batch, u1_batch), dim=2)  # concatenate along input dimension\n",
    "    u_batch, y_batch, t_batch = u_batch.to(\"cpu\"), y_batch.to(\"cpu\") , t_batch.to(\"cpu\")\n",
    "    \n",
    "\n",
    "    closed_loop_REN_2.eval()\n",
    "    _, y_hat = closed_loop_REN_2(x0, u_batch, t_batch)\n",
    "    \n",
    "    loss_batch_val = MSE(y_batch, y_hat)\n",
    "\n",
    "    loss_val_epoch += loss_batch_val.item()\n",
    "    \n",
    "    y_batch_np = scaler_glucose.denormalize(y_batch.detach().cpu()).numpy()\n",
    "    y_hat_np = scaler_glucose.denormalize(y_hat.detach().cpu()).numpy()\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(time, y_batch_np[0, :, 0], label=\"Real Output\", color=\"blue\")\n",
    "plt.plot(time, y_hat_np[0, :, 0], label=\"Predicted Output\", linestyle=\"--\", color=\"orange\")\n",
    "plt.title(f\"Train Set\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Output Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "non_lin_sys_id",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
